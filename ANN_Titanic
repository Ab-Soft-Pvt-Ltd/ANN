import pandas as pd
import tensorflow as tf

from google.colab import files
uploaded = files.upload()

import io
df = pd.read_csv(io.BytesIO(uploaded['train.csv']))

df.shape

df.head()

df.info()

df.isnull().sum()


df['Age'] = df['Age'].fillna(df['Age'].mean())
df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])
df['Cabin'] = df['Cabin'].fillna(df['Cabin'].mode()[0])

df.isnull().sum()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()


df_col = df.columns
for i in df_col:
  df[i] = le.fit_transform(df[i])

df.head(3)

#inputs = df.drop('Survived', axis=1)
#target = df['Survived']

inputs = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]
target = df['Survived']

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
inputs = pd.DataFrame(sc.fit_transform(inputs), columns=inputs.columns)
inputs.head(3)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(inputs, target, test_size=0.2, random_state=42)

!pip install -q keras

from keras.models import Sequential 
from keras.layers import Dense, Dropout, BatchNormalization
from keras.callbacks import EarlyStopping
from keras.regularizers import L2

ann = Sequential()
ann.add(Dense(units=12, activation='relu', input_dim=7, kernel_regularizer=L2(l2=0.01)))
ann.add(BatchNormalization())
ann.add(Dense(units=8, activation='relu'))
ann.add(BatchNormalization()) 
ann.add(Dense(units=4, activation='relu'))
ann.add(BatchNormalization())
ann.add(Dense(units=2, activation='relu'))
ann.add(BatchNormalization())
ann.add(Dense(units=1, activation='sigmoid'))

X_train.shape

for i in range(1, 712):
  if (712%i==0):
    print(i)

ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
history = ann.fit(X_train, y_train, batch_size=89, epochs=200, validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)])

score, train_acc = ann.evaluate(X_train, y_train, batch_size=89)
print(score)
print("Training Accuracy: ",train_acc)

from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = ann.predict(X_test)
y_pred = (y_pred > 0.5)
cm = confusion_matrix(y_test, y_pred)
test_acc = accuracy_score(y_test, y_pred)


print(cm)
print("Test Accuracy: ", test_acc)

print("Training Accuracy: ",round(train_acc*100,2))
print("Test Accuracy: ", round(test_acc*100,2))
print('DIfference', round(abs(train_acc*100-test_acc*100),2))

from matplotlib import pyplot as plt
#history = model1.fit(train_x, train_y,validation_split = 0.1, epochs=50, batch_size=4)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

pd.DataFrame(history.history).plot(figsize=(8,5))
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

p = sns.heatmap(pd.DataFrame(cm), annot=True, cmap="RdYlGn" ,fmt='g')
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')

from sklearn.metrics import classification_report
print(classification_report(y_test,y_pred))

from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score

fpr, tpr, thresholds = roc_curve(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred)
print(roc_auc)

plt.plot([0,1],[0,1],'k--')
plt.plot(fpr,tpr, label='ANN')
plt.xlabel('fpr')
plt.ylabel('tpr')
plt.title('ROC curve')
plt.show()
